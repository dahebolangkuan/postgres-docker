# PostgreSQL Docker 镜像扩展插件详细分析

## 镜像概述

这是一个基于 PostgreSQL 17.6 的定制化Docker镜像，采用多阶段构建策略，包含13个常用扩展插件，涵盖图数据库、时序数据、向量检索、审计、定时任务等多个应用场景。

---

## 构建架构分析

### 第一阶段（Builder Stage）
- **基础镜像**: postgres:17.6
- **目的**: 编译需要从源码构建的扩展（pg_parquet）
- **工具链**: Rust/Cargo + pgrx 0.16.0
- **输出**: 编译后的 .so 库文件和扩展定义文件

### 第二阶段（Final Stage）
- **基础镜像**: postgres:17.6
- **目的**: 安装预编译扩展包并复制自编译扩展
- **健康检查**: 每30秒检查PostgreSQL可用性

---

## 扩展插件详细说明

### 1. AGE (Apache AGE) - 图数据库扩展

**用途**: 在PostgreSQL中提供图数据库功能，支持Cypher查询语言（类似Neo4j）

**应用场景**:
- 社交网络关系分析
- 知识图谱构建
- 推荐系统
- 欺诈检测

**使用示例**:

```sql
-- 创建并启用AGE扩展
CREATE EXTENSION age;
LOAD 'age';
SET search_path = ag_catalog, "$user", public;

-- 创建图
SELECT create_graph('social_network');

-- 创建节点
SELECT * FROM cypher('social_network', $$
    CREATE (a:Person {name: 'Alice', age: 30})
    RETURN a
$$) as (a agtype);

SELECT * FROM cypher('social_network', $$
    CREATE (b:Person {name: 'Bob', age: 25})
    RETURN b
$$) as (b agtype);

-- 创建关系
SELECT * FROM cypher('social_network', $$
    MATCH (a:Person {name: 'Alice'}), (b:Person {name: 'Bob'})
    CREATE (a)-[r:FRIENDS_WITH {since: 2020}]->(b)
    RETURN r
$$) as (r agtype);

-- 查询关系
SELECT * FROM cypher('social_network', $$
    MATCH (a:Person)-[r:FRIENDS_WITH]->(b:Person)
    RETURN a.name, b.name, r.since
$$) as (friend1 agtype, friend2 agtype, since agtype);

-- 最短路径查询
SELECT * FROM cypher('social_network', $$
    MATCH p = shortestPath((a:Person {name: 'Alice'})-[*]-(b:Person {name: 'Bob'}))
    RETURN p
$$) as (path agtype);
```

---

### 2. pg_cron - 定时任务调度器

**用途**: 在PostgreSQL内部实现类似Linux cron的定时任务调度功能

**应用场景**:
- 定期数据清理
- 自动备份
- 定期数据汇总统计
- 定期报表生成

**配置要求**:
```ini
# postgresql.conf
shared_preload_libraries = 'pg_cron'
cron.database_name = 'postgres'
```

**使用示例**:

```sql
-- 创建扩展
CREATE EXTENSION pg_cron;

-- 每天凌晨3点清理过期数据
SELECT cron.schedule('清理过期日志', '0 3 * * *', $$
    DELETE FROM logs WHERE created_at < NOW() - INTERVAL '90 days';
$$);

-- 每小时执行一次数据汇总
SELECT cron.schedule('hourly-stats', '0 * * * *', $$
    INSERT INTO hourly_stats (hour, total_sales)
    SELECT date_trunc('hour', NOW()), SUM(amount)
    FROM sales
    WHERE created_at >= NOW() - INTERVAL '1 hour';
$$);

-- 每周一早上8点生成周报
SELECT cron.schedule('weekly-report', '0 8 * * 1', $$
    CALL generate_weekly_report();
$$);

-- 每5分钟检查并归档数据
SELECT cron.schedule('archive-data', '*/5 * * * *', $$
    CALL archive_old_records();
$$);

-- 查看所有定时任务
SELECT * FROM cron.job;

-- 查看任务执行历史
SELECT * FROM cron.job_run_details ORDER BY start_time DESC LIMIT 10;

-- 取消定时任务
SELECT cron.unschedule(1);  -- 1是任务ID
```

---

### 3. jsquery - JSON查询扩展

**用途**: 提供强大的JSON数据查询语言，比原生JSONB操作符更灵活

**应用场景**:
- 复杂JSON结构查询
- 半结构化数据存储
- 配置信息管理
- 灵活的文档数据库功能

**使用示例**:

```sql
-- 创建扩展
CREATE EXTENSION jsquery;

-- 创建测试表
CREATE TABLE products (
    id SERIAL PRIMARY KEY,
    data JSONB
);

-- 插入示例数据
INSERT INTO products (data) VALUES
('{"name": "Laptop", "price": 1200, "specs": {"ram": "16GB", "cpu": "i7"}, "tags": ["electronics", "computer"]}'),
('{"name": "Phone", "price": 800, "specs": {"ram": "8GB", "cpu": "A15"}, "tags": ["electronics", "mobile"]}'),
('{"name": "Desk", "price": 300, "category": "furniture", "tags": ["office", "home"]}');

-- 基本查询：查找价格大于500的产品
SELECT data->>'name', data->>'price'
FROM products
WHERE data @@ 'price > 500'::jsquery;

-- 嵌套属性查询：查找RAM为16GB的产品
SELECT data->>'name'
FROM products
WHERE data @@ 'specs.ram = "16GB"'::jsquery;

-- 数组查询：查找带有"electronics"标签的产品
SELECT data->>'name'
FROM products
WHERE data @@ 'tags.# = "electronics"'::jsquery;

-- 复合查询
SELECT data->>'name', data->'specs'
FROM products
WHERE data @@ 'price >= 500 AND specs.ram IN ("8GB", "16GB")'::jsquery;

-- 通配符查询
SELECT data->>'name'
FROM products
WHERE data @@ 'tags.# LIKE "elect%"'::jsquery;

-- 创建GIN索引以加速查询
CREATE INDEX products_data_jsquery_idx ON products USING GIN (data jsonb_path_ops);
```

---

### 4. pg_partman - 分区表管理工具

**用途**: 自动化管理PostgreSQL表分区，支持时间和序列分区

**应用场景**:
- 大规模时序数据管理
- 日志表自动分区
- 数据归档策略
- 提升查询性能

**使用示例**:

```sql
-- 创建扩展
CREATE EXTENSION pg_partman;

-- 创建父表（按日期分区）
CREATE TABLE events (
    id BIGSERIAL,
    event_time TIMESTAMPTZ NOT NULL,
    event_type TEXT,
    user_id INTEGER,
    data JSONB
) PARTITION BY RANGE (event_time);

-- 创建分区管理配置
SELECT partman.create_parent(
    p_parent_table => 'public.events',
    p_control => 'event_time',
    p_type => 'native',
    p_interval => 'daily',
    p_premake => 7,  -- 提前创建7天的分区
    p_start_partition => '2024-01-01'
);

-- 设置保留策略（保留90天）
UPDATE partman.part_config
SET retention = '90 days',
    retention_keep_table = false
WHERE parent_table = 'public.events';

-- 手动运行维护（通常通过pg_cron自动化）
SELECT partman.run_maintenance('public.events');

-- 自动化分区维护（配合pg_cron）
SELECT cron.schedule('partition-maintenance', '0 3 * * *', $$
    SELECT partman.run_maintenance_proc();
$$);

-- 查看分区信息
SELECT * FROM partman.part_config;

-- 查看所有分区
SELECT 
    schemaname,
    tablename,
    pg_size_pretty(pg_total_relation_size(schemaname||'.'||tablename)) AS size
FROM pg_tables
WHERE tablename LIKE 'events_p%'
ORDER BY tablename;

-- 按序列分区示例
CREATE TABLE orders (
    id BIGSERIAL,
    order_id BIGINT NOT NULL,
    customer_id INTEGER,
    amount NUMERIC,
    created_at TIMESTAMPTZ
) PARTITION BY RANGE (order_id);

SELECT partman.create_parent(
    p_parent_table => 'public.orders',
    p_control => 'order_id',
    p_type => 'native',
    p_interval => '1000000',  -- 每100万订单一个分区
    p_premake => 4
);
```

---

### 5. pg_hint_plan - 查询优化提示

**用途**: 允许通过SQL注释强制PostgreSQL使用特定的查询执行计划

**应用场景**:
- 优化特定查询性能
- 绕过优化器错误估算
- 测试不同执行计划
- 生产环境临时优化

**配置要求**:
```ini
# postgresql.conf
shared_preload_libraries = 'pg_hint_plan'
```

**使用示例**:

```sql
-- 创建扩展
CREATE EXTENSION pg_hint_plan;

-- 示例表
CREATE TABLE users (id INT PRIMARY KEY, name TEXT, city TEXT);
CREATE TABLE orders (id INT, user_id INT, amount NUMERIC);
CREATE INDEX idx_orders_user ON orders(user_id);

-- 强制使用特定索引
/*+
    IndexScan(orders idx_orders_user)
*/
SELECT * FROM orders WHERE user_id = 100;

-- 强制使用嵌套循环连接
/*+
    NestLoop(users orders)
*/
SELECT u.name, o.amount
FROM users u
JOIN orders o ON u.id = o.user_id
WHERE u.city = 'Beijing';

-- 强制使用哈希连接
/*+
    HashJoin(users orders)
*/
SELECT u.name, o.amount
FROM users u
JOIN orders o ON u.id = o.user_id;

-- 设置连接顺序
/*+
    Leading(orders users)
    HashJoin(orders users)
*/
SELECT u.name, o.amount
FROM users u
JOIN orders o ON u.id = o.user_id
WHERE o.amount > 1000;

-- 禁用特定扫描方式
/*+
    SeqScan(orders)
    NoIndexScan(orders)
*/
SELECT * FROM orders WHERE user_id > 50;

-- 设置并行度
/*+
    Parallel(orders 4)
*/
SELECT COUNT(*) FROM orders;

-- 查看hint是否生效
EXPLAIN (ANALYZE, BUFFERS) /*+
    IndexScan(orders idx_orders_user)
*/
SELECT * FROM orders WHERE user_id = 100;
```

---

### 6. pgaudit - 审计日志扩展

**用途**: 提供详细的数据库操作审计功能，符合合规要求

**应用场景**:
- 安全审计
- 合规性要求（GDPR、HIPAA等）
- 数据访问追踪
- 安全事件调查

**配置要求**:
```ini
# postgresql.conf
shared_preload_libraries = 'pgaudit'
pgaudit.log = 'all'  # 或 'read', 'write', 'ddl', 'role' 等
pgaudit.log_catalog = off
pgaudit.log_relation = on
pgaudit.log_parameter = on
```

**使用示例**:

```sql
-- 创建扩展
CREATE EXTENSION pgaudit;

-- 审计所有操作
ALTER SYSTEM SET pgaudit.log = 'all';
SELECT pg_reload_conf();

-- 仅审计写操作（INSERT, UPDATE, DELETE）
ALTER SYSTEM SET pgaudit.log = 'write';
SELECT pg_reload_conf();

-- 仅审计DDL操作
ALTER SYSTEM SET pgaudit.log = 'ddl';
SELECT pg_reload_conf();

-- 针对特定用户的审计
ALTER ROLE sensitive_user SET pgaudit.log = 'all';

-- 针对特定数据库的审计
ALTER DATABASE production_db SET pgaudit.log = 'read, write';

-- 对象级审计（审计特定表）
CREATE TABLE sensitive_data (
    id SERIAL PRIMARY KEY,
    ssn TEXT,
    credit_card TEXT
);

-- 为表创建审计规则
SELECT pgaudit.log_relation('sensitive_data', 'SELECT, INSERT, UPDATE, DELETE');

-- 查看审计日志（在PostgreSQL日志文件中）
-- 日志示例：
-- LOG: AUDIT: SESSION,1,1,WRITE,INSERT,TABLE,public.users,"INSERT INTO users (name) VALUES ('Alice')"

-- 审计角色变更
ALTER SYSTEM SET pgaudit.log = 'role';
-- 现在所有 CREATE ROLE, ALTER ROLE, DROP ROLE 等操作都会被审计

-- 临时禁用会话级审计
SET pgaudit.log = 'none';

-- 恢复审计
RESET pgaudit.log;
```

---

### 7. pgauditlogtofile - 审计日志文件输出

**用途**: 将pgaudit的审计日志输出到独立文件，便于分析和归档

**应用场景**:
- 审计日志独立管理
- 日志分析和监控
- 长期归档
- 与SIEM系统集成

**配置要求**:
```ini
# postgresql.conf
shared_preload_libraries = 'pgaudit, pgauditlogtofile'
pgauditlogtofile.log_directory = '/var/log/pgaudit'
pgauditlogtofile.log_filename = 'pgaudit-%Y-%m-%d.log'
pgauditlogtofile.log_rotation_age = '1d'
pgauditlogtofile.log_rotation_size = '100MB'
```

**使用示例**:

```sql
-- 创建扩展
CREATE EXTENSION pgauditlogtofile;

-- 配置独立的审计日志文件
ALTER SYSTEM SET pgauditlogtofile.log_directory = '/var/log/pgaudit';
ALTER SYSTEM SET pgauditlogtofile.log_filename = 'audit-%Y%m%d_%H%M%S.log';
ALTER SYSTEM SET pgauditlogtofile.log_rotation_age = '1440';  -- 24小时轮转
ALTER SYSTEM SET pgauditlogtofile.log_rotation_size = '102400';  -- 100MB轮转
SELECT pg_reload_conf();

-- 执行需要审计的操作
INSERT INTO sensitive_data (ssn, credit_card) 
VALUES ('123-45-6789', '4111-1111-1111-1111');

-- 审计日志会写入 /var/log/pgaudit/audit-20260112_150000.log
-- 格式类似：
-- 2026-01-12 15:00:01.234 UTC [12345] LOG: AUDIT: SESSION,1,1,WRITE,INSERT,TABLE,public.sensitive_data,...

-- 使用外部工具分析审计日志
-- grep "sensitive_data" /var/log/pgaudit/audit-*.log
-- awk '/DELETE/ {print}' /var/log/pgaudit/audit-*.log
```

---

### 8. pgpcre - Perl兼容正则表达式

**用途**: 提供PCRE（Perl Compatible Regular Expressions）支持，比PostgreSQL原生正则更强大

**应用场景**:
- 复杂文本匹配
- 数据验证
- 文本提取和转换
- 日志分析

**使用示例**:

```sql
-- 创建扩展
CREATE EXTENSION pgpcre;

-- 基本匹配
SELECT 'hello@example.com' ~ '^[a-zA-Z0-9._%+-]+@[a-zA-Z0-9.-]+\.[a-zA-Z]{2,}$' AS valid_email;

-- 提取匹配内容
SELECT regexp_matches('订单号：ORD-2024-001', 'ORD-\d{4}-\d{3}');

-- 替换文本
SELECT regexp_replace('Phone: (123) 456-7890', '\((\d{3})\)\s*(\d{3})-(\d{4})', '\1-\2-\3');
-- 结果: Phone: 123-456-7890

-- 批量数据清理
UPDATE customers
SET phone = regexp_replace(phone, '[^0-9]', '', 'g')
WHERE phone ~ '[^0-9]';

-- 复杂模式匹配：提取URL参数
SELECT regexp_matches(
    'https://example.com/page?id=123&name=test&active=true',
    '[?&](\w+)=([^&]+)',
    'g'
) AS params;

-- 验证密码强度（至少8位，包含大小写字母和数字）
SELECT 
    password,
    password ~ '^(?=.*[a-z])(?=.*[A-Z])(?=.*\d).{8,}$' AS is_strong
FROM user_passwords;

-- 提取IP地址
SELECT regexp_matches(
    'User connected from 192.168.1.100 at 2024-01-12',
    '\b(?:\d{1,3}\.){3}\d{1,3}\b'
) AS ip_address;

-- 多行文本处理
CREATE TABLE logs (id SERIAL, message TEXT);
INSERT INTO logs (message) VALUES 
('ERROR: Database connection failed'),
('WARNING: High memory usage'),
('INFO: Backup completed');

SELECT 
    message,
    CASE 
        WHEN message ~ '^ERROR:' THEN 'error'
        WHEN message ~ '^WARNING:' THEN 'warning'
        WHEN message ~ '^INFO:' THEN 'info'
    END AS log_level
FROM logs;
```

---

### 9. pgq3 - 队列系统

**用途**: 实现数据库级别的消息队列系统，支持事件驱动架构

**应用场景**:
- 异步任务处理
- 事件溯源
- 数据同步
- 微服务解耦

**使用示例**:

```sql
-- 创建扩展
CREATE EXTENSION pgq;

-- 创建队列
SELECT pgq.create_queue('order_queue');
SELECT pgq.create_queue('email_queue');

-- 注册消费者
SELECT pgq.register_consumer('order_queue', 'order_processor');
SELECT pgq.register_consumer('email_queue', 'email_sender');

-- 发布事件到队列
SELECT pgq.insert_event('order_queue', 'new_order', 
    '{"order_id": 12345, "customer_id": 789, "amount": 99.99}'::jsonb::text
);

SELECT pgq.insert_event('email_queue', 'send_welcome', 
    '{"email": "user@example.com", "name": "John Doe"}'::jsonb::text
);

-- 批量发布事件
DO $$
DECLARE
    i INTEGER;
BEGIN
    FOR i IN 1..100 LOOP
        PERFORM pgq.insert_event('order_queue', 'bulk_order', 
            format('{"order_id": %s}', i)
        );
    END LOOP;
END $$;

-- 消费者获取事件批次
SELECT pgq.next_batch('order_queue', 'order_processor') AS batch_id;

-- 获取批次中的事件
SELECT 
    ev_id,
    ev_type,
    ev_data,
    ev_time
FROM pgq.get_batch_events(123)  -- 123是batch_id
ORDER BY ev_id;

-- 处理完成后标记批次
SELECT pgq.finish_batch(123);

-- 如果处理失败，可以重试特定事件
SELECT pgq.event_retry(123, 456, 60);  -- batch_id, event_id, retry_after_seconds

-- 查看队列状态
SELECT * FROM pgq.get_queue_info();

-- 查看消费者状态
SELECT * FROM pgq.get_consumer_info();

-- 取消注册消费者
SELECT pgq.unregister_consumer('order_queue', 'order_processor');

-- 删除队列
SELECT pgq.drop_queue('order_queue');

-- 实际应用示例：订单处理队列
CREATE OR REPLACE FUNCTION process_orders()
RETURNS void AS $$
DECLARE
    batch_id BIGINT;
    event_rec RECORD;
BEGIN
    -- 获取一批事件
    batch_id := pgq.next_batch('order_queue', 'order_processor');
    
    IF batch_id IS NULL THEN
        RETURN;  -- 没有待处理事件
    END IF;
    
    -- 处理每个事件
    FOR event_rec IN 
        SELECT * FROM pgq.get_batch_events(batch_id)
    LOOP
        BEGIN
            -- 处理订单逻辑
            INSERT INTO processed_orders (order_data, processed_at)
            VALUES (event_rec.ev_data::jsonb, NOW());
            
        EXCEPTION WHEN OTHERS THEN
            -- 记录错误并重试
            INSERT INTO error_log (event_id, error_msg)
            VALUES (event_rec.ev_id, SQLERRM);
            
            PERFORM pgq.event_retry(batch_id, event_rec.ev_id, 300);
        END;
    END LOOP;
    
    -- 完成批次
    PERFORM pgq.finish_batch(batch_id);
END;
$$ LANGUAGE plpgsql;

-- 使用pg_cron定期执行
SELECT cron.schedule('process-order-queue', '* * * * *', 'SELECT process_orders();');
```

---

### 10. pgvector - 向量数据库扩展

**用途**: 存储和查询向量数据，支持AI/ML应用的相似度搜索

**应用场景**:
- 语义搜索
- 推荐系统
- 图像相似度检索
- RAG（检索增强生成）应用
- 异常检测

**使用示例**:

```sql
-- 创建扩展
CREATE EXTENSION vector;

-- 创建向量表（存储文档嵌入）
CREATE TABLE documents (
    id SERIAL PRIMARY KEY,
    title TEXT,
    content TEXT,
    embedding vector(1536)  -- OpenAI ada-002模型的维度
);

-- 插入带向量的数据
INSERT INTO documents (title, content, embedding) VALUES
('PostgreSQL入门', 'PostgreSQL是一个强大的开源关系数据库', 
 '[0.1, 0.2, 0.3, ...]'::vector),  -- 实际使用时是1536维
('Python教程', 'Python是一种流行的编程语言',
 '[0.15, 0.25, 0.35, ...]'::vector);

-- 创建向量索引（HNSW或IVFFlat）
CREATE INDEX ON documents USING hnsw (embedding vector_cosine_ops);
-- 或使用IVFFlat
CREATE INDEX ON documents USING ivfflat (embedding vector_l2_ops) WITH (lists = 100);

-- 余弦相似度搜索（推荐用于归一化向量）
SELECT 
    title,
    content,
    1 - (embedding <=> '[0.12, 0.22, 0.32, ...]'::vector) AS similarity
FROM documents
ORDER BY embedding <=> '[0.12, 0.22, 0.32, ...]'::vector
LIMIT 5;

-- L2距离搜索
SELECT 
    title,
    embedding <-> '[0.1, 0.2, 0.3, ...]'::vector AS distance
FROM documents
ORDER BY embedding <-> '[0.1, 0.2, 0.3, ...]'::vector
LIMIT 5;

-- 内积搜索
SELECT 
    title,
    (embedding <#> '[0.1, 0.2, 0.3, ...]'::vector) * -1 AS inner_product
FROM documents
ORDER BY embedding <#> '[0.1, 0.2, 0.3, ...]'::vector
LIMIT 5;

-- 实际应用：问答系统
CREATE TABLE qa_knowledge (
    id SERIAL PRIMARY KEY,
    question TEXT,
    answer TEXT,
    embedding vector(1536)
);

-- 向量化查询并找到最相似的问题
-- 假设用户问题已经通过API转换为向量
WITH user_query AS (
    SELECT '[...]'::vector AS query_embedding
)
SELECT 
    question,
    answer,
    1 - (embedding <=> query_embedding) AS relevance
FROM qa_knowledge, user_query
WHERE 1 - (embedding <=> query_embedding) > 0.7  -- 相似度阈值
ORDER BY embedding <=> query_embedding
LIMIT 3;

-- 图像相似度检索
CREATE TABLE images (
    id SERIAL PRIMARY KEY,
    filename TEXT,
    description TEXT,
    feature_vector vector(2048)  -- ResNet等模型的特征向量
);

-- 查找相似图像
SELECT 
    filename,
    description
FROM images
ORDER BY feature_vector <-> '[...]'::vector
LIMIT 10;

-- 向量运算
SELECT 
    '[1,2,3]'::vector + '[4,5,6]'::vector AS vector_add,
    '[1,2,3]'::vector - '[4,5,6]'::vector AS vector_subtract,
    '[1,2,3]'::vector * '[4,5,6]'::vector AS element_wise_mult;

-- 向量维度
SELECT vector_dims('[1,2,3,4,5]'::vector);  -- 返回 5

-- 组合过滤和向量搜索
SELECT 
    title,
    content,
    1 - (embedding <=> '[...]'::vector) AS similarity
FROM documents
WHERE content LIKE '%数据库%'  -- 先过滤
ORDER BY embedding <=> '[...]'::vector
LIMIT 5;
```

---

### 11. prefix - 前缀树查询

**用途**: 提供高效的前缀匹配和范围查询，特别适合IP地址、电话号码等场景

**应用场景**:
- IP地址段管理
- 电话号码归属地查询
- 前缀路由
- CIDR网络查询

**使用示例**:

```sql
-- 创建扩展
CREATE EXTENSION prefix;

-- 创建IP范围表
CREATE TABLE ip_ranges (
    id SERIAL PRIMARY KEY,
    network cidr,
    country TEXT,
    isp TEXT
);

-- 插入IP段数据
INSERT INTO ip_ranges (network, country, isp) VALUES
('192.168.0.0/16', 'Private', 'Internal'),
('10.0.0.0/8', 'Private', 'Internal'),
('8.8.8.0/24', 'US', 'Google'),
('1.1.1.0/24', 'US', 'Cloudflare');

-- 创建prefix索引
CREATE INDEX ON ip_ranges USING gist (network inet_ops);

-- 查询IP所属范围
SELECT country, isp
FROM ip_ranges
WHERE network >> '192.168.1.100'::inet
ORDER BY masklen(network) DESC
LIMIT 1;

-- 电话号码前缀表
CREATE TABLE phone_prefixes (
    prefix TEXT PRIMARY KEY,
    region TEXT,
    operator TEXT
);

INSERT INTO phone_prefixes VALUES
('1301', '北京', '移动'),
('1381', '上海', '电信'),
('1591', '广东', '联通');

-- 前缀匹配查询
CREATE INDEX ON phone_prefixes (prefix text_pattern_ops);

SELECT region, operator
FROM phone_prefixes
WHERE '13012345678' LIKE prefix || '%'
ORDER BY length(prefix) DESC
LIMIT 1;

-- 使用prefix类型（如果扩展支持）
CREATE TABLE routes (
    id SERIAL PRIMARY KEY,
    prefix prefix_range,  -- 自定义类型
    nexthop INET,
    description TEXT
);

-- 范围查询示例
SELECT *
FROM ip_ranges
WHERE network >>= '192.168.0.0/24';  -- 包含此子网的所有网段

-- 查找重叠的网段
SELECT a.network AS network1, b.network AS network2
FROM ip_ranges a, ip_ranges b
WHERE a.id < b.id
  AND a.network && b.network;  -- 重叠检测
```

---

### 12. TimescaleDB - 时序数据库扩展

**用途**: 将PostgreSQL转换为高性能时序数据库，专门优化时间序列数据存储和查询

**应用场景**:
- IoT传感器数据
- 监控指标存储
- 金融市场数据
- 日志分析
- 应用性能监控

**配置要求**:
```ini
# postgresql.conf
shared_preload_libraries = 'timescaledb'
```

**使用示例**:

```sql
-- 创建扩展
CREATE EXTENSION timescaledb;

-- 创建普通表
CREATE TABLE sensor_data (
    time TIMESTAMPTZ NOT NULL,
    sensor_id INTEGER NOT NULL,
    temperature DOUBLE PRECISION,
    humidity DOUBLE PRECISION,
    pressure DOUBLE PRECISION
);

-- 转换为超表（hypertable）
SELECT create_hypertable('sensor_data', 'time');

-- 插入数据
INSERT INTO sensor_data VALUES
('2024-01-12 10:00:00+00', 1, 22.5, 45.0, 1013.25),
('2024-01-12 10:01:00+00', 1, 22.6, 45.2, 1013.30),
('2024-01-12 10:00:00+00', 2, 23.1, 50.0, 1012.80);

-- 时间桶聚合（5分钟间隔）
SELECT 
    time_bucket('5 minutes', time) AS bucket,
    sensor_id,
    AVG(temperature) AS avg_temp,
    MAX(temperature) AS max_temp,
    MIN(temperature) AS min_temp
FROM sensor_data
WHERE time > NOW() - INTERVAL '1 hour'
GROUP BY bucket, sensor_id
ORDER BY bucket DESC;

-- 创建连续聚合（物化视图）
CREATE MATERIALIZED VIEW sensor_data_hourly
WITH (timescaledb.continuous) AS
SELECT 
    time_bucket('1 hour', time) AS hour,
    sensor_id,
    AVG(temperature) AS avg_temp,
    MAX(temperature) AS max_temp,
    MIN(temperature) AS min_temp,
    COUNT(*) AS sample_count
FROM sensor_data
GROUP BY hour, sensor_id;

-- 添加刷新策略（自动更新物化视图）
SELECT add_continuous_aggregate_policy('sensor_data_hourly',
    start_offset => INTERVAL '3 hours',
    end_offset => INTERVAL '1 hour',
    schedule_interval => INTERVAL '1 hour'
);

-- 数据保留策略（自动删除旧数据）
SELECT add_retention_policy('sensor_data', INTERVAL '90 days');

-- 压缩策略（自动压缩旧数据）
ALTER TABLE sensor_data SET (
    timescaledb.compress,
    timescaledb.compress_segmentby = 'sensor_id'
);

SELECT add_compression_policy('sensor_data', INTERVAL '7 days');

-- 时间加权平均
SELECT 
    sensor_id,
    average(time_weight('Linear', time, temperature)) AS time_weighted_avg
FROM sensor_data
WHERE time > NOW() - INTERVAL '24 hours'
GROUP BY sensor_id;

-- 缺失数据插值
SELECT 
    time_bucket_gapfill('1 minute', time) AS minute,
    sensor_id,
    interpolate(AVG(temperature)) AS temperature
FROM sensor_data
WHERE time > NOW() - INTERVAL '1 hour'
  AND sensor_id = 1
GROUP BY minute, sensor_id
ORDER BY minute;

-- 金融数据示例：股票行情
CREATE TABLE stock_prices (
    time TIMESTAMPTZ NOT NULL,
    symbol TEXT NOT NULL,
    open NUMERIC,
    high NUMERIC,
    low NUMERIC,
    close NUMERIC,
    volume BIGINT
);

SELECT create_hypertable('stock_prices', 'time');

-- K线数据查询（日线）
SELECT 
    time_bucket('1 day', time) AS day,
    symbol,
    first(open, time) AS open,
    max(high) AS high,
    min(low) AS low,
    last(close, time) AS close,
    sum(volume) AS volume
FROM stock_prices
WHERE symbol = 'AAPL'
  AND time > NOW() - INTERVAL '30 days'
GROUP BY day, symbol
ORDER BY day;

-- 查看分区（chunks）
SELECT * FROM timescaledb_information.chunks
WHERE hypertable_name = 'sensor_data';

-- 查看压缩状态
SELECT * FROM timescaledb_information.compression_settings
WHERE hypertable_name = 'sensor_data';

-- 实时数据 + 历史数据查询优化
SELECT 
    time_bucket('1 minute', time) AS minute,
    AVG(temperature) AS avg_temp
FROM sensor_data
WHERE time > NOW() - INTERVAL '1 hour'
GROUP BY minute
ORDER BY minute DESC;
```

---

### 13. pg_parquet - Parquet文件支持

**用途**: 直接在PostgreSQL中读写Apache Parquet列式存储文件，实现数据湖集成

**应用场景**:
- 数据湖交互
- 大数据分析
- 数据导出优化
- 与Spark/Hadoop生态集成
- 列式存储性能优化

**使用示例**:

```sql
-- 创建扩展
CREATE EXTENSION pg_parquet;

-- 从Parquet文件读取数据
CREATE FOREIGN TABLE sales_parquet (
    order_id BIGINT,
    customer_id INTEGER,
    product_id INTEGER,
    amount NUMERIC,
    order_date DATE
)
SERVER parquet_server
OPTIONS (filename '/data/sales.parquet');

-- 查询Parquet文件
SELECT 
    product_id,
    SUM(amount) AS total_sales,
    COUNT(*) AS order_count
FROM sales_parquet
WHERE order_date >= '2024-01-01'
GROUP BY product_id
ORDER BY total_sales DESC;

-- 将PostgreSQL表导出为Parquet
COPY (
    SELECT * FROM orders WHERE created_at > '2024-01-01'
) TO '/export/orders_2024.parquet'
WITH (FORMAT parquet);

-- 批量导出分区数据
COPY (
    SELECT * FROM sensor_data 
    WHERE time >= '2024-01-01' AND time < '2024-02-01'
) TO '/export/sensor_data_202401.parquet'
WITH (FORMAT parquet, compression 'snappy');

-- 导入Parquet文件到PostgreSQL
CREATE TABLE imported_data AS
SELECT * FROM parquet_scan('/data/import/*.parquet');

-- 使用列式查询优化（仅读取需要的列）
SELECT order_id, amount
FROM sales_parquet
WHERE amount > 1000;  -- 仅扫描order_id和amount列

-- 与外部数据湖集成
CREATE FOREIGN TABLE datalake_events (
    event_id BIGINT,
    event_type TEXT,
    user_id INTEGER,
    timestamp TIMESTAMPTZ,
    properties JSONB
)
SERVER parquet_server
OPTIONS (
    filename '/datalake/events/year=2024/month=01/*.parquet',
    use_mmap 'true'
);

-- 联合查询：数据库 + 数据湖
SELECT 
    u.username,
    COUNT(e.event_id) AS event_count
FROM users u
LEFT JOIN datalake_events e ON u.id = e.user_id
WHERE e.timestamp > NOW() - INTERVAL '7 days'
GROUP BY u.username;

-- 分区导出（按月）
DO $$
DECLARE
    start_date DATE := '2024-01-01';
    end_date DATE;
    filename TEXT;
BEGIN
    FOR i IN 0..11 LOOP
        end_date := start_date + INTERVAL '1 month';
        filename := format('/export/data_%s.parquet', to_char(start_date, 'YYYYMM'));
        
        EXECUTE format('
            COPY (
                SELECT * FROM events 
                WHERE event_time >= %L AND event_time < %L
            ) TO %L
            WITH (FORMAT parquet, compression ''snappy'')
        ', start_date, end_date, filename);
        
        start_date := end_date;
    END LOOP;
END $$;

-- 性能对比：Parquet vs CSV
-- Parquet优势：
-- 1. 列式存储，查询特定列更快
-- 2. 内置压缩，存储空间小
-- 3. 支持复杂数据类型（嵌套结构）
-- 4. 保留schema信息

-- 读取嵌套JSON数据的Parquet
CREATE FOREIGN TABLE nested_parquet (
    id BIGINT,
    user_info JSONB,
    tags TEXT[]
)
SERVER parquet_server
OPTIONS (filename '/data/nested.parquet');

SELECT 
    id,
    user_info->>'name' AS user_name,
    user_info->'address'->>'city' AS city,
    tags
FROM nested_parquet;
```

---

## 配置文件示例

### docker-compose.yml

```yaml
version: '3.8'

services:
  postgres:
    build: .
    image: postgres-extended:17.6
    container_name: postgres-extended
    environment:
      POSTGRES_PASSWORD: mysecretpassword
      POSTGRES_DB: myapp
      # TimescaleDB配置
      TIMESCALEDB_TELEMETRY: 'off'
    ports:
      - "5432:5432"
    volumes:
      - postgres_data:/var/lib/postgresql/data
      - ./init-scripts:/docker-entrypoint-initdb.d
      - ./parquet-data:/data  # Parquet文件目录
      - ./pgaudit-logs:/var/log/pgaudit  # 审计日志目录
    command: >
      postgres
      -c shared_preload_libraries='timescaledb,pg_cron,pgaudit,pgauditlogtofile,pg_hint_plan'
      -c cron.database_name='postgres'
      -c pgaudit.log='all'
      -c pgauditlogtofile.log_directory='/var/log/pgaudit'
      -c max_connections=200
      -c shared_buffers=2GB
      -c work_mem=16MB
    healthcheck:
      test: ["CMD-SHELL", "pg_isready -U postgres"]
      interval: 10s
      timeout: 5s
      retries: 5

volumes:
  postgres_data:
```

### 初始化脚本示例 (init-scripts/01-extensions.sql)

```sql
-- 创建所有扩展
CREATE EXTENSION IF NOT EXISTS age;
CREATE EXTENSION IF NOT EXISTS pg_cron;
CREATE EXTENSION IF NOT EXISTS jsquery;
CREATE EXTENSION IF NOT EXISTS pg_partman;
CREATE EXTENSION IF NOT EXISTS pg_hint_plan;
CREATE EXTENSION IF NOT EXISTS pgaudit;
CREATE EXTENSION IF NOT EXISTS pgauditlogtofile;
CREATE EXTENSION IF NOT EXISTS pgpcre;
CREATE EXTENSION IF NOT EXISTS pgq;
CREATE EXTENSION IF NOT EXISTS vector;
CREATE EXTENSION IF NOT EXISTS prefix;
CREATE EXTENSION IF NOT EXISTS timescaledb;
CREATE EXTENSION IF NOT EXISTS pg_parquet;

-- 设置AGE
LOAD 'age';
SET search_path = ag_catalog, "$user", public;

-- 创建演示图
SELECT create_graph('demo_graph');

-- 配置pg_partman schema
CREATE SCHEMA IF NOT EXISTS partman;
GRANT ALL ON SCHEMA partman TO postgres;
```

---

## 性能优化建议

### 1. 索引策略
- **pgvector**: 对于百万级以上数据，使用HNSW索引；千万级以上考虑IVFFlat
- **TimescaleDB**: 自动创建时间索引，额外索引按查询模式添加
- **jsquery**: 为JSONB字段创建GIN索引

### 2. 内存配置
```ini
# postgresql.conf
shared_buffers = 25% of RAM
work_mem = (Total RAM - shared_buffers) / (max_connections * 3)
maintenance_work_mem = 1GB 到 2GB
effective_cache_size = 75% of RAM
```

### 3. 并发连接
- 使用连接池（PgBouncer、Pgpool-II）
- max_connections建议值：100-200

### 4. 扩展特定优化
- **TimescaleDB**: 启用压缩和保留策略
- **pg_partman**: 配合pg_cron自动维护分区
- **pgvector**: 归一化向量以使用余弦相似度

---

## 监控和维护

### 查看扩展状态
```sql
-- 列出所有已安装扩展
SELECT * FROM pg_extension;

-- 查看扩展版本
SELECT extname, extversion FROM pg_extension ORDER BY extname;

-- 查看扩展占用空间
SELECT 
    extname,
    pg_size_pretty(pg_relation_size(extnamespace::regnamespace)) AS size
FROM pg_extension;
```

### 性能监控
```sql
-- 查看慢查询
SELECT 
    calls,
    total_exec_time,
    mean_exec_time,
    query
FROM pg_stat_statements
ORDER BY mean_exec_time DESC
LIMIT 10;

-- TimescaleDB统计
SELECT * FROM timescaledb_information.hypertables;
SELECT * FROM timescaledb_information.dimensions;

-- pgvector索引状态
SELECT 
    schemaname,
    tablename,
    indexname,
    pg_size_pretty(pg_relation_size(indexrelid)) AS index_size
FROM pg_stat_user_indexes
WHERE indexname LIKE '%vector%';
```

---

## 安全建议

1. **审计配置**: 启用pgaudit和pgauditlogtofile记录敏感操作
2. **角色隔离**: 为不同应用创建独立数据库用户
3. **加密连接**: 启用SSL/TLS
4. **定期备份**: 使用pg_dump或物理备份
5. **版本更新**: 定期更新扩展以获取安全补丁

---

## 常见问题排查

### 扩展加载失败
```sql
-- 检查shared_preload_libraries配置
SHOW shared_preload_libraries;

-- 查看错误日志
-- 在容器内: tail -f /var/log/postgresql/postgresql-*.log
```

### 性能问题
```sql
-- 检查缓存命中率
SELECT 
    sum(heap_blks_hit) / (sum(heap_blks_hit) + sum(heap_blks_read)) AS cache_hit_ratio
FROM pg_statio_user_tables;

-- 应该 > 0.99
```

### 磁盘空间
```sql
-- 查看表大小
SELECT 
    schemaname,
    tablename,
    pg_size_pretty(pg_total_relation_size(schemaname||'.'||tablename)) AS size
FROM pg_tables
ORDER BY pg_total_relation_size(schemaname||'.'||tablename) DESC
LIMIT 20;
```

---

## 总结

这个PostgreSQL Docker镜像集成了13个强大的扩展，覆盖了现代应用开发的主要需求：

| 类别 | 扩展 | 核心价值 |
|------|------|----------|
| 图数据库 | AGE | 社交网络、知识图谱 |
| 任务调度 | pg_cron | 自动化运维 |
| JSON查询 | jsquery | 半结构化数据 |
| 分区管理 | pg_partman | 海量数据管理 |
| 查询优化 | pg_hint_plan | 性能调优 |
| 安全审计 | pgaudit, pgauditlogtofile | 合规性 |
| 正则表达式 | pgpcre | 文本处理 |
| 消息队列 | pgq3 | 异步处理 |
| 向量检索 | pgvector | AI应用 |
| 前缀匹配 | prefix | 网络管理 |
| 时序数据 | TimescaleDB | IoT、监控 |
| 数据湖集成 | pg_parquet | 大数据分析 |

**推荐使用场景**:
- **SaaS应用**: TimescaleDB + pgvector + pgaudit
- **AI应用**: pgvector + pg_parquet + TimescaleDB
- **物联网平台**: TimescaleDB + pg_partman + pg_cron
- **社交网络**: AGE + pgvector + pgq3
- **企业应用**: pgaudit + pg_cron + pg_partman

通过合理组合这些扩展，可以将PostgreSQL打造成一个功能全面的企业级数据平台。
